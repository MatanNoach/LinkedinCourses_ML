{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of loading pre-trained Image Recognition model\n",
    "\n",
    "Working with Keras, there are few types of pre-trained models you can load (according to 2017):\n",
    "\n",
    "- VGG (Visual Geometry Group at the university of Oxford)\n",
    "- ResNet50 (Microsoft Research)\n",
    "- Inception-v3 (Google)\n",
    "- Xception (Frncois Chollet, author of Keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet import preprocess_input, decode_predictions\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ResNet50()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"datasets\\\\05\"\n",
    "# Loading the image with the proper size for ResNet50\n",
    "img = load_img(os.path.join(base_path, \"bay.jpg\"), target_size=(224, 224))\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image to array\n",
    "x = img_to_array(img)\n",
    "# Add a forth dimension - transform a single image to an array containing a single image\n",
    "# The ResNet50 was expects to get an array of images and outputs an array of results\n",
    "x = np.expand_dims(x, axis=0)\n",
    "# Scale the image values to the ones that are used by ResNet50\n",
    "x = preprocess_input(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 2us/step\n",
      "This image is an image of: \n",
      "n09428293 - seashore: 0.57 likelihood\n",
      "n09332890 - lakeside: 0.29 likelihood\n",
      "n03216828 - dock: 0.08 likelihood\n",
      "n02894605 - breakwater: 0.04 likelihood\n",
      "n09399592 - promontory: 0.01 likelihood\n",
      "n02981792 - catamaran: 0.00 likelihood\n",
      "n09421951 - sandbar: 0.00 likelihood\n",
      "n04483307 - trimaran: 0.00 likelihood\n",
      "n03933933 - pier: 0.00 likelihood\n"
     ]
    }
   ],
   "source": [
    "# Return a 1000 array of LIKELIHOODS of predictions. From that we need to extract the class with the most likelihood\n",
    "predictions = model.predict(x)\n",
    "predicted_classes = decode_predictions(predictions, top=9)\n",
    "print(\"This image is an image of: \")\n",
    "\n",
    "for imagenet_id, name, likelihhod in predicted_classes[0]:\n",
    "    print(f\"{imagenet_id} - {name}: {likelihhod:.2f} likelihood\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a68054a1377440dd3f78f1f273580d7335c2e20b564bc770fee5dc8903a7f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
