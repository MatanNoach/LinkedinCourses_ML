{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Using a Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import os\n",
    "base_path = \"datasets\\\\03\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df = pd.read_csv(os.path.join(\n",
    "    base_path, \"sales_data_training_scaled.csv\"))\n",
    "X = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y = training_data_df[['total_earnings']].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network\n",
    "# input_dim = 9 since we have 9 values in our X data (10 in the training data but we removed the total_earnings column)\n",
    "# The name parameter is used for logging (see details below)\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(50, input_dim=9, activation='relu', name='input'),\n",
    "    tf.keras.layers.Dense(100, activation='relu', name='hidden_layer_1'),\n",
    "    tf.keras.layers.Dense(50, activation='relu', name='hidden_layer_3'),\n",
    "    tf.keras.layers.Dense(1, activation='linear', name='output')\n",
    "])\n",
    "# Creating the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 - 0s - loss: 0.0548 - 309ms/epoch - 24ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 0.0146 - 15ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 0.0067 - 17ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 0.0033 - 17ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 0.0016 - 19ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 9.9985e-04 - 17ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "13/13 - 0s - loss: 7.2893e-04 - 17ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "13/13 - 0s - loss: 5.6979e-04 - 18ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "13/13 - 0s - loss: 4.5399e-04 - 17ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "13/13 - 0s - loss: 3.5033e-04 - 18ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "13/13 - 0s - loss: 2.9537e-04 - 17ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "13/13 - 0s - loss: 2.5981e-04 - 16ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "13/13 - 0s - loss: 2.3013e-04 - 19ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "13/13 - 0s - loss: 1.9837e-04 - 17ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "13/13 - 0s - loss: 1.8643e-04 - 18ms/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "13/13 - 0s - loss: 1.6881e-04 - 17ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "13/13 - 0s - loss: 1.3993e-04 - 17ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "13/13 - 0s - loss: 1.1799e-04 - 17ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "13/13 - 0s - loss: 1.1021e-04 - 18ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "13/13 - 0s - loss: 1.0493e-04 - 16ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "13/13 - 0s - loss: 9.7490e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "13/13 - 0s - loss: 8.7563e-05 - 14ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "13/13 - 0s - loss: 7.7800e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "13/13 - 0s - loss: 8.0223e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "13/13 - 0s - loss: 7.4507e-05 - 17ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "13/13 - 0s - loss: 6.8274e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "13/13 - 0s - loss: 5.9833e-05 - 18ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "13/13 - 0s - loss: 5.9946e-05 - 15ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "13/13 - 0s - loss: 5.5513e-05 - 17ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "13/13 - 0s - loss: 4.8406e-05 - 15ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "13/13 - 0s - loss: 5.0057e-05 - 14ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "13/13 - 0s - loss: 4.5394e-05 - 20ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "13/13 - 0s - loss: 4.2174e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "13/13 - 0s - loss: 4.2127e-05 - 15ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "13/13 - 0s - loss: 5.6182e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "13/13 - 0s - loss: 5.5461e-05 - 17ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "13/13 - 0s - loss: 4.8690e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "13/13 - 0s - loss: 4.2000e-05 - 17ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "13/13 - 0s - loss: 3.9637e-05 - 15ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "13/13 - 0s - loss: 4.1491e-05 - 18ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "13/13 - 0s - loss: 3.7613e-05 - 18ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "13/13 - 0s - loss: 4.0005e-05 - 17ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "13/13 - 0s - loss: 4.0248e-05 - 15ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "13/13 - 0s - loss: 3.2296e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "13/13 - 0s - loss: 3.0863e-05 - 15ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "13/13 - 0s - loss: 4.2382e-05 - 20ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "13/13 - 0s - loss: 3.6771e-05 - 16ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "13/13 - 0s - loss: 2.6582e-05 - 18ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "13/13 - 0s - loss: 2.4147e-05 - 15ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "13/13 - 0s - loss: 2.5408e-05 - 15ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb97e745b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=50, shuffle=True, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the test was 2.734712506935466e-05\n"
     ]
    }
   ],
   "source": [
    "test_data_df = pd.read_csv(os.path.join(\n",
    "    base_path, \"sales_data_testing_scaled.csv\"))\n",
    "X_test = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_test = test_data_df[['total_earnings']].values\n",
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(f\"The MSE for the test was {test_error_rate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with the Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83620524"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"datasets\\\\04\"\n",
    "data_to_predict = pd.read_csv(os.path.join(\n",
    "    base_path, \"proposed_new_product.csv\")).values\n",
    "prediction = model.predict(data_to_predict)\n",
    "prediction = prediction[0][0]\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversing the preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257552.00283064574"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse the scaling from the original data (the scaling we did on the preprocess)\n",
    "prediction = prediction+0.115913\n",
    "prediction = prediction/0.0000036968\n",
    "prediction\n",
    "# This will estimate a total_earning of 258876\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"trained_model.h5\")\n",
    "# print(\"model saved to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a saved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model(filepath=\"trained_model.h5\")\n",
    "# # Now you can use this model to make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging and Monitoring the Model\n",
    "\n",
    "### TensorFlow uses a web app called TensorBoard that lets you monitor you model\n",
    "\n",
    "- NOTE - The 'Graph' options does not work when the fitting has 'verbose=2' parameter\n",
    "\n",
    "### Visualizing Training Process\n",
    "\n",
    "In order to visualize the training process, you need to give each run a name, add it to the log_dir as a paramter (like usign python format) and then on each run you will create a different log file.\n",
    "TensorBoard in the 'Scalars' tab will create a chart comparing different runs. This can compare different runs and help you optimize the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8928e-05\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5151e-05\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.3079e-05\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.1332e-05\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2159e-05\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9073e-05\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.1578e-05\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.5302e-05\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.3581e-05\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.8298e-05\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6219e-05\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.9581e-05\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.1055e-05\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.2762e-05\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.4931e-05\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2792e-04\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4832e-04\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.4304e-04\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.7742e-05\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.1805e-05\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.8330e-05\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.9501e-05\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.2309e-05\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.5126e-05\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8703e-05\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.0904e-05\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.7437e-05\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 957us/step - loss: 4.0650e-05\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.8815e-05\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.5539e-05\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5836e-05\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8013e-05\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0053e-05\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.8527e-05\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6218e-05\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.7678e-05\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1687e-05\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.1750e-05\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.3324e-05\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.6357e-05\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7388e-05\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.9360e-05\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2922e-05\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0215e-05\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3893e-05\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5839e-05\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.6852e-05\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5678e-05\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5712e-05\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.7579e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb97eef070>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras will only log details on the training process but not the structure of the model.\n",
    "# write_graph - allow the logger to log the structure of the model. Takes a lot of space\n",
    "# histogram_freq - the frequency of writing statistics. This time it is every 5 epochs\n",
    "logger = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs\", write_graph=True, histogram_freq=5)\n",
    "# The model needs to be trained again since we create the logger just now. We also need to add 'name' parameter for each layer\n",
    "model.fit(X, Y, epochs=50, shuffle=True, verbose=1, callbacks=[logger])\n",
    "# In order to view the logs in tensorboard, you need to run the following command in terminal:\n",
    "# tensorboard --logdir='working_with_keras\\logs'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a68054a1377440dd3f78f1f273580d7335c2e20b564bc770fee5dc8903a7f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
