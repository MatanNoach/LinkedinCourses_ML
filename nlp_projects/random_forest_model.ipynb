{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model for NLP\n",
    "\n",
    "### We will use a basic Random Forest model to analyze our SMS Spam Collection dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Raw Text, and perform all preprocessing steps we did before (cleaning the text, feature engineering and text vectorizing steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...  8094  8095  \\\n",
       "0       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1        49     4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2        62     3.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3        28     7.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4       135     4.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   8096  8097  8098  8099  8100  8101  8102  8103  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import os\n",
    "base_path = 'datasets'\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(os.path.join(base_path,\"SMSSpamCollection.tsv\"), sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "\n",
    "X_features = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using K-Fold cross validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97486535, 0.98114901, 0.97484277, 0.96675651, 0.97304582])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# n_jobs = -1 - means we can run everything in parallel\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "# Split the training set to 5 subsets\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf,X=X_features,y=data['label'],cv=k_fold,scoring='accuracy',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Holdout Test Set method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split to train and test sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_features,data['label'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\Projects\\LinkedinCourses_ML\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=50,max_depth=20,n_jobs=-1)\n",
    "rf2_model = rf2.fit(X=x_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.06759716769808131, 'body_len'),\n",
       " (0.05236945935131036, 7350),\n",
       " (0.0430298966460655, 1803),\n",
       " (0.03135372877876165, 4796),\n",
       " (0.02353401544537904, 3134),\n",
       " (0.02129444375633566, 2031),\n",
       " (0.02019702873181215, 6746),\n",
       " (0.019996640655553843, 7027),\n",
       " (0.019344240311034152, 5724),\n",
       " (0.01845058202116578, 690)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the most important features\n",
    "# Body Length is the most important feature\n",
    "# The other column names are numbers due to how the vecrotization process occurres (assign a number to each column)\n",
    "sorted(zip(rf2_model.feature_importances_,x_train.columns),reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.577 / Accuracy: 0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\Projects\\LinkedinCourses_ML\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predict on every x_test\n",
    "y_pred = rf2_model.predict(x_test)\n",
    "# Getting the evaluation metrics with \"spam\" as the important label\n",
    "precision,recall,fscore,support = score(y_test,y_pred,pos_label='spam',average='binary')\n",
    "precision_r = round(precision,3)\n",
    "recall_r = round(recall,3)\n",
    "accuracy = round((y_pred==y_test).sum()/len(y_pred),3)\n",
    "print(f\"Precision: {precision_r} / Recall: {recall_r} / Accuracy: {accuracy}\")\n",
    "# From the results:\n",
    "# 100% of not-spam were correctly identified as not-span - great!\n",
    "# 57% of spam were correctly identified as spam - not great since 43% of spam went into the inbox\n",
    "# 94% of all emails went into our email, were correctly identified as spam/not-spam - great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "Defining a grid of hyperparameters and changing the hyperparameters of model by the grid to find the best combination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the same training process as before\n",
    "def train_rf(n_est,depth):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est,n_jobs=-1)\n",
    "    rf_model = rf.fit(x_train,y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    precision,recall,fscore,support = score(y_test,y_pred,pos_label='spam',average='binary')\n",
    "    precision_r = round(precision,3)\n",
    "    recall_r = round(recall,3)\n",
    "    accuracy = round((y_pred==y_test).sum()/len(y_pred),3)\n",
    "    print(f\"Est: {n_est}, Depth {depth} ----- Precision: {precision_r} / Recall: {recall_r} / Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10, Depth 10 ----- Precision: 0.981 / Recall: 0.746 / Accuracy: 0.966\n",
      "Est: 10, Depth 20 ----- Precision: 1.0 / Recall: 0.803 / Accuracy: 0.975\n",
      "Est: 10, Depth 30 ----- Precision: 0.991 / Recall: 0.761 / Accuracy: 0.969\n",
      "Est: 10, Depth None ----- Precision: 1.0 / Recall: 0.768 / Accuracy: 0.97\n",
      "Est: 50, Depth 10 ----- Precision: 1.0 / Recall: 0.831 / Accuracy: 0.978\n",
      "Est: 50, Depth 20 ----- Precision: 1.0 / Recall: 0.817 / Accuracy: 0.977\n",
      "Est: 50, Depth 30 ----- Precision: 0.992 / Recall: 0.824 / Accuracy: 0.977\n",
      "Est: 50, Depth None ----- Precision: 0.992 / Recall: 0.831 / Accuracy: 0.978\n",
      "Est: 100, Depth 10 ----- Precision: 1.0 / Recall: 0.817 / Accuracy: 0.977\n",
      "Est: 100, Depth 20 ----- Precision: 0.991 / Recall: 0.81 / Accuracy: 0.975\n",
      "Est: 100, Depth 30 ----- Precision: 1.0 / Recall: 0.803 / Accuracy: 0.975\n",
      "Est: 100, Depth None ----- Precision: 1.0 / Recall: 0.81 / Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "# Supress sklearn warnings (something about the column names not string)\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# Testing the training process for different combinations\n",
    "for n_est in [10,50,100]:\n",
    "    for depth in [10,20,30,None]:\n",
    "        train_rf(n_est,depth)\n",
    "# It's hard to tell which model had the best results, but I would choose Est:100 and Depth: None (no depth limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Grid Search with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.517458</td>\n",
       "      <td>2.106193</td>\n",
       "      <td>0.101224</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.983842</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.964061</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.973412</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.199205</td>\n",
       "      <td>1.109820</td>\n",
       "      <td>0.186668</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.972695</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.365716</td>\n",
       "      <td>0.625012</td>\n",
       "      <td>0.118424</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.964061</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.971796</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27.392953</td>\n",
       "      <td>0.435013</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>0.023004</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.971258</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.711262</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.964061</td>\n",
       "      <td>0.969641</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10      17.517458      2.106193         0.101224        0.006583   \n",
       "8       32.199205      1.109820         0.186668        0.011874   \n",
       "7       15.365716      0.625012         0.118424        0.014606   \n",
       "11      27.392953      0.435013         0.163121        0.023004   \n",
       "3        0.711262      0.084473         0.006241        0.000714   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "10            None                150   \n",
       "8               90                300   \n",
       "7               90                150   \n",
       "11            None                300   \n",
       "3               60                 10   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.983842   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.977558   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.975763   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.975763   \n",
       "3      {'max_depth': 60, 'n_estimators': 10}           0.978456   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "10           0.977558           0.973944           0.964061   \n",
       "8            0.974865           0.973944           0.967655   \n",
       "7            0.977558           0.975741           0.964061   \n",
       "11           0.973070           0.973046           0.964960   \n",
       "3            0.970377           0.968553           0.966757   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "10           0.967655         0.973412        0.007026                1  \n",
       "8            0.969452         0.972695        0.003629                2  \n",
       "7            0.965858         0.971796        0.005650                3  \n",
       "11           0.969452         0.971258        0.003734                4  \n",
       "3            0.964061         0.969641        0.004876                5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators':[10,150,300],\n",
    "    'max_depth':[30,60,90,None]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf,params,cv=5,n_jobs=-1)\n",
    "gs_fit = gs.fit(X_tfidf,data['label'])\n",
    "# Focus on the mean_test_score\n",
    "results = pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a68054a1377440dd3f78f1f273580d7335c2e20b564bc770fee5dc8903a7f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
